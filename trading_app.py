import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
from sklearn.decomposition import PCA
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, BaggingRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.base import clone
from mlxtend.evaluate import bias_variance_decomp
from statsmodels.tsa.stattools import adfuller
import matplotlib.pyplot as plt
import warnings

# Suprimir avisos para uma sa√≠da mais limpa no Streamlit
warnings.filterwarnings("ignore")

st.set_page_config(layout="wide", page_title="An√°lise de Estrat√©gia de Trading ML")

st.title("üìà An√°lise de Estrat√©gia de Trading com Machine Learning")
st.markdown("""
Esta aplica√ß√£o permite que voc√™ explore uma estrat√©gia de trading baseada em Machine Learning,
utilizando a decomposi√ß√£o Bias-Vari√¢ncia para sele√ß√£o de modelos e a estacionariza√ß√£o de s√©ries temporais.
""")

# --- Fun√ß√µes do Pipeline (Mantidas as mesmas, adaptadas para o Streamlit) ---

@st.cache_data(show_spinner="A baixar dados financeiros...")
def download_data(ticker: str, period: str) -> pd.DataFrame:
    """Baixa dados hist√≥ricos do Yahoo Finance."""
    df = yf.download(ticker, period=period, multi_level_index=False)
    df.reset_index(inplace=True)
    return df

@st.cache_data(show_spinner="A criar indicadores t√©cnicos...")
def create_technical_indicators(df: pd.DataFrame) -> pd.DataFrame:
    """Calcula uma s√©rie de indicadores t√©cnicos como features."""
    price = df['Close']
    high = df['High']
    low = df['Low']
    close = df['Close']
    volume = df['Volume']
    indicators = pd.DataFrame(index=df.index)

    indicators['sma_5'] = price.rolling(window=5).mean()
    indicators['sma_10'] = price.rolling(window=10).mean()
    indicators['ema_5'] = price.ewm(span=5).mean()
    indicators['ema_10'] = price.ewm(span=10).mean()
    indicators['momentum_5'] = price - price.shift(5)
    indicators['momentum_10'] = price - price.shift(10)
    indicators['roc_5'] = price.pct_change(5)
    indicators['roc_10'] = price.pct_change(10)
    indicators['std_5'] = price.rolling(window=5).std()
    indicators['std_10'] = price.rolling(window=10).std()

    delta = price.diff()
    up = delta.clip(lower=0)
    down = -delta.clip(upper=0)
    avg_gain = up.rolling(window=14).mean()
    avg_loss = down.rolling(window=14).mean()
    rs = avg_gain / (avg_loss + 1e-10)
    indicators['rsi_14'] = 100 - (100 / (1 + rs))

    typical_price = (high + low + close) / 3
    vwap = (typical_price * volume).cumsum() / volume.cumsum()
    indicators['vwap'] = vwap

    # OBV - Usando opera√ß√µes vetorizadas do Pandas
    obv = pd.Series(0, index=close.index)
    price_change = close.diff()
    obv[price_change > 0] = volume[price_change > 0]
    obv[price_change < 0] = -volume[price_change < 0]
    indicators['obv'] = obv.cumsum().fillna(0)

    plus_dm = high.diff()
    minus_dm = low.diff()
    plus_dm[plus_dm < 0] = 0
    minus_dm[minus_dm > 0] = 0
    tr = pd.concat([
        high - low,
        abs(high - close.shift()),
        abs(low - close.shift())
    ], axis=1).max(axis=1)
    atr = tr.rolling(14).mean()
    plus_di = 100 * (plus_dm.ewm(alpha=1/14).mean() / atr)
    minus_di = 100 * (-minus_dm.ewm(alpha=1/14).mean() / atr)
    dx = 100 * abs(plus_di - minus_di) / (plus_di + minus_di + 1e-10)
    indicators['adx_14'] = dx.ewm(alpha=1/14).mean()

    indicators['atr_14'] = atr
    sma20 = price.rolling(20).mean()
    std20 = price.rolling(20).std()
    indicators['bollinger_upper'] = sma20 + 2 * std20
    indicators['bollinger_lower'] = sma20 - 2 * std20
    ema12 = price.ewm(span=12).mean()
    ema26 = price.ewm(span=26).mean()
    indicators['macd'] = ema12 - ema26
    tp = (high + low + close) / 3
    cci = (tp - tp.rolling(20).mean()) / (0.015 * tp.rolling(20).std())
    indicators['cci_20'] = cci
    highest_high = high.rolling(14).max()
    lowest_low = low.rolling(14).min()
    indicators['williams_r'] = -100 * (highest_high - close) / (highest_high - lowest_low + 1e-10)
    low14 = low.rolling(14).min()
    high14 = high.rolling(14).max()
    indicators['stochastic_k'] = 100 * (close - low14) / (high14 - low14 + 1e-10)

    return indicators.dropna().reset_index(drop=True)

@st.cache_data
def compute_target(df: pd.DataFrame) -> pd.Series:
    """Calcula a vari√°vel alvo (retorno percentual de 5 dias)."""
    return df['Close'].pct_change(periods=5).shift(-5)

@st.cache_data(show_spinner="A executar otimiza√ß√£o walk-forward e extra√ß√£o de features...")
def walk_forward_with_pca_vif(data, model, window_size=250, step_size=1, n_components=4):
    """Executa a otimiza√ß√£o walk-forward com PCA e VIF."""
    predictions = []
    prediction_indices = []
    last_scaler = None
    last_pca = None
    last_vif_scores = None
    last_trained_model = None
    last_selected_pc_indices = None
    
    for i in range(window_size, len(data) - 5, step_size):
        train_data = data.iloc[i - window_size:i]
        test_row = data.iloc[i]

        X_raw = train_data.drop(columns=['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Target'], errors='ignore')
        y_train = train_data['Target']

        if X_raw.empty or y_train.empty:
            continue

        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X_raw)

        pca = PCA(n_components=n_components)
        X_pca = pca.fit_transform(X_scaled)

        vif_data = pd.DataFrame(X_pca, columns=[f'PC{j+1}' for j in range(n_components)])
        
        selected_pc_indices = np.array([True] * vif_data.shape[1]) # Default to all if VIF not applicable
        if vif_data.shape[1] > 1:
            vif_scores = [variance_inflation_factor(vif_data.values, j) for j in range(vif_data.shape[1])]
            selected_pc_indices = np.array(vif_scores) < 3
        
        selected_pcs = vif_data.iloc[:, selected_pc_indices]

        test_raw = test_row.drop(labels=['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Target'], errors='ignore').values.reshape(1, -1)
        test_scaled = scaler.transform(test_raw)
        test_pca = pca.transform(test_scaled)
        test_vif_df = pd.DataFrame(test_pca, columns=[f'PC{j+1}' for j in range(n_components)])
        test_selected = test_vif_df.iloc[:, selected_pc_indices]

        if selected_pcs.empty or test_selected.empty:
            continue

        model_clone = clone(model)
        model_clone.fit(selected_pcs, y_train)
        prediction = model_clone.predict(test_selected)[0]
        predictions.append(prediction)
        prediction_indices.append(i)

        last_scaler = scaler
        last_pca = pca
        last_vif_scores = vif_scores if 'vif_scores' in locals() else None
        last_trained_model = model_clone
        last_selected_pc_indices = selected_pc_indices 

    pred_series = pd.Series(data=np.nan, index=data.index)
    if prediction_indices:
        pred_series.iloc[prediction_indices] = predictions
    
    return pred_series, last_scaler, last_pca, last_vif_scores, last_trained_model, last_selected_pc_indices

@st.cache_data(show_spinner="A executar backtesting da estrat√©gia...")
def backtest_strategy(final_data, initial_capital=10000, capital_deployed=0.2):
    """Simula a estrat√©gia de trading."""
    trade_log = []
    for i in range(len(final_data) - 5):
        prediction = final_data.iloc[i]['Predictions']
        if pd.isna(prediction) or prediction == 0:
            continue

        direction = 'Long' if prediction > 0 else 'Short'
        entry_price = final_data.iloc[i + 1]['Open']
        exit_price = final_data.iloc[i + 5]['Close']

        if direction == 'Long':
            trade_return = (exit_price - entry_price) / entry_price
        else:
            trade_return = (entry_price - exit_price) / entry_price

        capital_change = capital_deployed * initial_capital * trade_return

        trade_log.append({
            'Signal_Day': final_data.iloc[i]['Date'],
            'Entry_Day': final_data.iloc[i + 1]['Date'],
            'Exit_Day': final_data.iloc[i + 5]['Date'],
            'Direction': direction,
            'Entry_Price': entry_price,
            'Exit_Price': exit_price,
            'Return': trade_return,
            'Capital_Change': capital_change
        })
    return pd.DataFrame(trade_log)

def sharpe_ratio(equity_curve, risk_free_rate=0.0):
    """Calcula o Sharpe Ratio anualizado."""
    daily_returns = equity_curve.pct_change().dropna()
    if daily_returns.std() == 0:
        return 0.0
    excess_returns = daily_returns - (risk_free_rate / 252)
    return np.sqrt(252) * excess_returns.mean() / excess_returns.std()

def max_drawdown(equity_curve):
    """Calcula o Maximum Drawdown."""
    peak = equity_curve.cummax()
    drawdown = (equity_curve - peak) / peak
    return drawdown.min(), drawdown

def get_models():
    """Retorna os modelos de regress√£o para avalia√ß√£o."""
    return {
        'LinearRegression': LinearRegression(),
        'Ridge': Ridge(),
        'DecisionTree': DecisionTreeRegressor(),
        'Bagging': BaggingRegressor(n_estimators=100, random_state=42),
        'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),
        'GradientBoosting': GradientBoostingRegressor(n_estimators=100, random_state=42)
    }

@st.cache_data(show_spinner="A executar decomposi√ß√£o Bias-Vari√¢ncia...")
def evaluate_bias_variance_all(_models, X, y, test_size=0.2, num_rounds=100): # Changed 'models' to '_models'
    """Executa a decomposi√ß√£o Bias-Vari√¢ncia para m√∫ltiplos modelos."""
    split = int(len(X) * (1 - test_size))
    X_train, X_test = X[:split], X[split:]
    y_train, y_test = y[:split], y[split:]

    results = {}
    for name, model in _models.items(): # Use _models here
        if len(y_train) == 0 or len(y_test) == 0:
            results[name] = {'Total Error': np.nan, 'Bias': np.nan, 'Variance': np.nan, 'Irreducible Error': np.nan}
            continue

        try:
            avg_loss, bias, var = bias_variance_decomp(
                model,
                X_train.values, y_train.values,
                X_test.values, y_test.values,
                loss='mse',
                num_rounds=num_rounds,
                random_seed=42
            )
            results[name] = {
                'Total Error': avg_loss,
                'Bias': bias,
                'Variance': var,
                'Irreducible Error': avg_loss - bias - var
            }
        except Exception as e:
            results[name] = {'Total Error': np.nan, 'Bias': np.nan, 'Variance': np.nan, 'Irreducible Error': np.nan}
    return pd.DataFrame(results).T

@st.cache_data(show_spinner="A verificar a ordem de integra√ß√£o dos preditores...")
def find_integration_order(series):
   """Determina a ordem de integra√ß√£o (d) usando o teste Augmented Dickey-Fuller."""
   d = 0
   current_series = series.copy()
   while True:
       if len(current_series.dropna()) < 20:
           return d
       result = adfuller(current_series.dropna(), autolag='AIC')
       if result[1] <= 0.05:
           return d
       current_series = current_series.diff().dropna()
       d += 1
       if d >= 2:
           return d

# --- Interface do Streamlit ---

with st.sidebar:
    st.header("Par√¢metros de Entrada")
    ticker_input = st.text_input("Ticker do Ativo (ex: PETR4.SA)", value="PETR4.SA")
    period_input = st.selectbox("Per√≠odo dos Dados", ["1y", "2y", "5y", "10y", "max"], index=2) # Default 5y

    st.markdown("---")
    st.subheader("Configura√ß√µes do Modelo")
    window_size_input = st.slider("Tamanho da Janela (Walk-Forward)", 100, 500, 250, 10)
    n_components_pca_input = st.slider("Componentes PCA (n_components)", 1, 10, 4, 1)
    
    st.markdown("---")
    if st.button("Executar An√°lise Completa"):
        st.session_state.run_analysis = True
    else:
        st.session_state.run_analysis = False

# Initialize session_state.run_analysis if it doesn't exist
if 'run_analysis' not in st.session_state:
    st.session_state.run_analysis = False

if st.session_state.run_analysis:
    st.info(f"A iniciar an√°lise para {ticker_input} ({period_input}). Isso pode demorar um pouco...")

    # --- Execu√ß√£o do Pipeline ---
    try:
        # 1. Download de Dados
        st.subheader("1. Download de Dados")
        data = download_data(ticker_input, period_input)
        if data.empty:
            st.error(f"N√£o foram encontrados dados para o ticker {ticker_input} no per√≠odo {period_input}. Por favor, verifique o ticker.")
            st.stop()
        st.write("Dados brutos baixados (primeiras 5 linhas):")
        st.dataframe(data.head())

        if len(data) < 30:
            st.warning(f"AVISO: Poucos dados ({len(data)} linhas) para an√°lise completa. Tente um per√≠odo maior.")
            st.stop()

        # 2. Cria√ß√£o de Indicadores T√©cnicos
        st.subheader("2. Cria√ß√£o de Indicadores T√©cnicos")
        indicators = create_technical_indicators(data)
        st.write("Indicadores t√©cnicos criados (informa√ß√µes):")
        # Use st.text to display info() output as preformatted text
        buffer = pd.io.common.StringIO()
        indicators.info(verbose=True, buf=buffer)
        st.text(buffer.getvalue())
        st.write("Primeiras 5 linhas dos indicadores:")
        st.dataframe(indicators.head())

        # 3. Alinhamento de Dados e Vari√°vel Alvo
        st.subheader("3. Alinhamento de Dados e Vari√°vel Alvo")
        data_aligned_for_indicators = data.iloc[-len(indicators):].reset_index(drop=True)
        data_merged = pd.concat([data_aligned_for_indicators, indicators], axis=1)
        data_merged['Target'] = compute_target(data_merged)
        data_merged.dropna(inplace=True)
        st.write("Dados alinhados e alvo calculado (informa√ß√µes):")
        buffer = pd.io.common.StringIO()
        data_merged.info(verbose=True, buf=buffer)
        st.text(buffer.getvalue())
        st.write("√öltimas 5 linhas dos dados mesclados com alvo:")
        st.dataframe(data_merged.tail())

        if data_merged.empty:
            st.error("Dados insuficientes ap√≥s o pr√©-processamento para continuar a an√°lise.")
            st.stop()

        # 4. Decomposi√ß√£o Bias-Vari√¢ncia (sem estacionariza√ß√£o)
        st.subheader("4. Decomposi√ß√£o Bias-Vari√¢ncia (sem estacionariza√ß√£o)")
        X_bv = data_merged.drop(columns=['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Target'], errors='ignore')
        y_bv = data_merged['Target']
        X_bv = X_bv.dropna()
        y_bv = y_bv.loc[X_bv.index]

        if not X_bv.empty and not y_bv.empty:
            models = get_models()
            bv_results = evaluate_bias_variance_all(_models=models, X=X_bv, y=y_bv, num_rounds=50) # Pass _models
            st.write("Resultados da Decomposi√ß√£o Bias-Vari√¢ncia (Sem Estacionariza√ß√£o):")
            st.dataframe(bv_results)
        else:
            st.warning("Dados insuficientes para a decomposi√ß√£o Bias-Vari√¢ncia (sem estacionariza√ß√£o).")

        # 5. Estacionariza√ß√£o dos Inputs
        st.subheader("5. Estacionariza√ß√£o dos Inputs")
        integration_orders = {}
        for col in indicators.columns:
            integration_orders[col] = find_integration_order(indicators[col].copy())
        integration_orders_df = pd.DataFrame.from_dict(integration_orders, orient='index', columns=['Integration Order'])
        integration_orders_df.index.name = 'Indicator'
        st.write("Ordens de integra√ß√£o dos indicadores:")
        st.dataframe(integration_orders_df["Integration Order"].value_counts().to_frame(name='Contagem'))

        differenced_indicators = indicators.copy()
        for indicator in integration_orders_df.index:
            order = integration_orders_df.loc[indicator, 'Integration Order']
            if order > 0:
                temp_series = indicators[indicator]
                for d_order in range(order):
                    temp_series = temp_series.diff().dropna()
                differenced_indicators[indicator] = temp_series
        differenced_indicators.dropna(inplace=True)
        st.write("Preditores estacionarizados (informa√ß√µes):")
        buffer = pd.io.common.StringIO()
        differenced_indicators.info(verbose=True, buf=buffer)
        st.text(buffer.getvalue())
        st.write("Primeiras 5 linhas dos preditores estacionarizados:")
        st.dataframe(differenced_indicators.head())

        # Verifica√ß√£o da estacionariza√ß√£o
        integration_orders_2 = {}
        for col in differenced_indicators.columns:
            integration_orders_2[col] = find_integration_order(differenced_indicators[col].copy())
        integration_orders_2_df = pd.DataFrame.from_dict(integration_orders_2, orient='index', columns=['Integration Order'])
        st.write("Ordens de integra√ß√£o ap√≥s estacionariza√ß√£o (verifica√ß√£o):")
        st.dataframe(integration_orders_2_df["Integration Order"].value_counts().to_frame(name='Contagem'))

        # 6. Alinhamento de Dados com Indicadores Estacionarizados
        st.subheader("6. Alinhamento de Dados com Indicadores Estacionarizados")
        data_aligned_for_differenced_indicators = data.iloc[-len(differenced_indicators):].reset_index(drop=True)
        data_merged_differenced = pd.concat([data_aligned_for_differenced_indicators, differenced_indicators], axis=1)
        data_merged_differenced['Target'] = compute_target(data_merged_differenced)
        data_merged_differenced.dropna(inplace=True)
        st.write("Dados alinhados com indicadores estacionarizados (informa√ß√µes):")
        buffer = pd.io.common.StringIO()
        data_merged_differenced.info(verbose=True, buf=buffer)
        st.text(buffer.getvalue())
        st.write("√öltimas 5 linhas dos dados mesclados e estacionarizados com alvo:")
        st.dataframe(data_merged_differenced.tail())

        if data_merged_differenced.empty:
            st.error("Dados insuficientes ap√≥s estacionariza√ß√£o e pr√©-processamento para continuar a an√°lise.")
            st.stop()

        # 7. Decomposi√ß√£o Bias-Vari√¢ncia (com estacionariza√ß√£o)
        st.subheader("7. Decomposi√ß√£o Bias-Vari√¢ncia (com estacionariza√ß√£o)")
        X_bv_differenced = data_merged_differenced.drop(columns=['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Target'], errors='ignore')
        y_bv_differenced = data_merged_differenced['Target']
        X_bv_differenced = X_bv_differenced.dropna()
        y_bv_differenced = y_bv_differenced.loc[X_bv_differenced.index]

        if not X_bv_differenced.empty and not y_bv_differenced.empty:
            bv_results_differenced = evaluate_bias_variance_all(_models=models, X=X_bv_differenced, y=y_bv_differenced, num_rounds=50) # Pass _models
            st.write("Resultados da Decomposi√ß√£o Bias-Vari√¢ncia (Com Preditores Estacionarizados):")
            st.dataframe(bv_results_differenced)
            st.info("O modelo GradientBoosting geralmente oferece um bom equil√≠brio e menor erro total.")
        else:
            st.warning("Dados insuficientes para a decomposi√ß√£o Bias-Vari√¢ncia (com estacionariza√ß√£o).")

        # 8. Rodar Previs√£o Walk-Forward
        st.subheader("8. Previs√£o Walk-Forward e Backtesting")
        model = GradientBoostingRegressor(n_estimators=100, random_state=42)
        pred_series_differenced, last_scaler, last_pca, last_vif_scores, last_trained_model, last_selected_pc_indices = \
            walk_forward_with_pca_vif(data_merged_differenced, model, window_size=window_size_input, n_components=n_components_pca_input)

        data_merged_differenced['Predictions'] = pred_series_differenced
        data_merged_differenced.dropna(subset=['Predictions'], inplace=True)

        final_data_differenced = data_merged_differenced[['Date', 'Open', 'Close', 'Target', 'Predictions']].copy()
        final_data_differenced['Date'] = pd.to_datetime(final_data_differenced['Date'])
        trades_df_differenced = backtest_strategy(final_data_differenced)

        st.subheader("Log de Trades")
        if not trades_df_differenced.empty:
            cols_to_round_to_two = ['Entry_Price', 'Exit_Price']
            trades_df_differenced[cols_to_round_to_two] = trades_df_differenced[cols_to_round_to_two].round(2)
            cols_to_round_to_four = ['Return', 'Capital_Change']
            trades_df_differenced[cols_to_round_to_four] = trades_df_differenced[cols_to_round_to_four].round(4)
            st.dataframe(trades_df_differenced.head(10))
            st.write(f"Total de trades gerados: {len(trades_df_differenced)}")
        else:
            st.warning("Nenhum trade foi gerado durante o backtesting. Isso pode ocorrer se houver dados insuficientes ou se o modelo n√£o gerar sinais de trading v√°lidos.")

        # 9. Curvas de Capital e M√©tricas de Desempenho
        st.subheader("9. Curvas de Capital e M√©tricas de Desempenho")
        initial_capital = 10000
        if not trades_df_differenced.empty:
            trades_df_differenced['Cumulative_Capital_Strategy'] = initial_capital + trades_df_differenced['Capital_Change'].cumsum()

        first_trade_date = trades_df_differenced['Entry_Day'].min() if not trades_df_differenced.empty else None
        last_trade_date = trades_df_differenced['Exit_Day'].max() if not trades_df_differenced.empty else None

        bh_data = pd.DataFrame()
        if first_trade_date and last_trade_date:
            bh_data = data_merged_differenced[(data_merged_differenced['Date'] >= first_trade_date) &
                                            (data_merged_differenced['Date'] <= last_trade_date)].copy()

        if not bh_data.empty:
            bh_initial_price = bh_data.iloc[0]['Close']
            bh_data['Cumulative_Capital_BH'] = initial_capital * (bh_data['Close'] / bh_initial_price)
        else:
            st.warning("N√£o h√° dados suficientes para calcular o Buy and Hold no per√≠odo dos trades.")

        st.markdown("#### Curva de Capital")
        fig_equity, ax_equity = plt.subplots(figsize=(12, 6))
        if not trades_df_differenced.empty and 'Cumulative_Capital_Strategy' in trades_df_differenced.columns:
            ax_equity.plot(trades_df_differenced['Exit_Day'], trades_df_differenced['Cumulative_Capital_Strategy'], label='Estrat√©gia de Trading', color='blue')
        if not bh_data.empty and 'Cumulative_Capital_BH' in bh_data.columns:
            ax_equity.plot(bh_data['Date'], bh_data['Cumulative_Capital_BH'], label='Buy and Hold', color='orange')
        ax_equity.set_title('Curva de Capital da Estrat√©gia vs. Buy and Hold')
        ax_equity.set_xlabel('Data')
        ax_equity.set_ylabel('Capital (R$)')
        ax_equity.legend()
        ax_equity.grid(True)
        st.pyplot(fig_equity)

        st.markdown("#### M√©tricas de Desempenho")
        col1, col2 = st.columns(2)

        with col1:
            st.markdown("**Estrat√©gia de Trading:**")
            if not trades_df_differenced.empty:
                final_capital_strategy = trades_df_differenced['Cumulative_Capital_Strategy'].iloc[-1]
                total_return_strategy = (final_capital_strategy - initial_capital) / initial_capital
                trading_days = (trades_df_differenced['Exit_Day'].iloc[-1] - trades_df_differenced['Entry_Day'].iloc[0]).days
                num_years = trading_days / 365.25
                cagr_strategy = ((final_capital_strategy / initial_capital) ** (1 / num_years)) - 1 if num_years > 0 else 0
                sharpe_strategy = sharpe_ratio(trades_df_differenced['Cumulative_Capital_Strategy'])
                max_dd_strategy, _ = max_drawdown(trades_df_differenced['Cumulative_Capital_Strategy'])
                profitable_trades = trades_df_differenced[trades_df_differenced['Return'] > 0]
                hit_ratio_strategy = len(profitable_trades) / len(trades_df_differenced) if len(trades_df_differenced) > 0 else 0
                avg_return_per_trade_strategy = trades_df_differenced['Return'].mean()

                st.write(f"Capital Final: R$ {final_capital_strategy:.2f}")
                st.write(f"Retorno Total: {total_return_strategy:.2%}")
                st.write(f"CAGR: {cagr_strategy:.2%}")
                st.write(f"Sharpe Ratio: {sharpe_strategy:.2f}")
                st.write(f"Max Drawdown: {max_dd_strategy:.2%}")
                st.write(f"Hit Ratio: {hit_ratio_strategy:.2%}")
                st.write(f"Retorno M√©dio por Trade: {avg_return_per_trade_strategy:.2%}")
            else:
                st.write("N√£o h√° trades para calcular as m√©tricas.")

        with col2:
            st.markdown("**Buy and Hold:**")
            if not bh_data.empty:
                final_capital_bh = bh_data['Cumulative_Capital_BH'].iloc[-1]
                total_return_bh = (final_capital_bh - initial_capital) / initial_capital
                cagr_bh = ((final_capital_bh / initial_capital) ** (1 / num_years)) - 1 if num_years > 0 else 0
                sharpe_bh = sharpe_ratio(bh_data['Cumulative_Capital_BH'])
                max_dd_bh, _ = max_drawdown(bh_data['Cumulative_Capital_BH'])

                st.write(f"Capital Final: R$ {final_capital_bh:.2f}")
                st.write(f"Retorno Total: {total_return_bh:.2%}")
                st.write(f"CAGR: {cagr_bh:.2%}")
                st.write(f"Sharpe Ratio: {sharpe_bh:.2f}")
                st.write(f"Max Drawdown: {max_dd_bh:.2%}")
            else:
                st.write("N√£o h√° dados para o Buy and Hold para calcular as m√©tricas.")

        if not trades_df_differenced.empty:
            st.markdown("#### Distribui√ß√£o dos Retornos por Trade")
            fig_hist, ax_hist = plt.subplots(figsize=(10, 5))
            ax_hist.hist(trades_df_differenced['Return'], bins=50, edgecolor='black')
            ax_hist.set_title('Distribui√ß√£o dos Retornos por Trade')
            ax_hist.set_xlabel('Retorno')
            ax_hist.set_ylabel('Frequ√™ncia')
            ax_hist.grid(True)
            st.pyplot(fig_hist)

        # 10. Previs√£o Futura
        st.subheader("10. Previs√£o Futura Baseada nos Dados Mais Recentes")
        if last_trained_model is not None and last_scaler is not None and last_pca is not None and last_selected_pc_indices is not None:
            if len(data) >= 30:
                temp_df_for_latest_indicators = data.iloc[-30:].copy()
            else:
                temp_df_for_latest_indicators = data.copy()

            latest_indicators_full = create_technical_indicators(temp_df_for_latest_indicators)

            if not latest_indicators_full.empty:
                latest_full_indicators_row = latest_indicators_full.iloc[-1]
                latest_differenced_indicators_for_prediction = latest_full_indicators_row.copy()
                
                for indicator_name, order in integration_orders.items():
                    if order > 0 and indicator_name in indicators.columns:
                        temp_series = indicators[indicator_name]
                        for d_order in range(order):
                            temp_series = temp_series.diff().dropna()
                        if not temp_series.empty:
                            latest_differenced_indicators_for_prediction[indicator_name] = temp_series.iloc[-1]
                        else:
                            latest_differenced_indicators_for_prediction.drop(indicator_name, inplace=True, errors='ignore')
                    elif indicator_name in latest_full_indicators_row.index:
                        latest_differenced_indicators_for_prediction[indicator_name] = latest_full_indicators_row[indicator_name]
                    else:
                        latest_differenced_indicators_for_prediction.drop(indicator_name, inplace=True, errors='ignore')
                
                X_latest_for_prediction = pd.DataFrame([latest_differenced_indicators_for_prediction]).dropna(axis=1)

                training_feature_columns = data_merged_differenced.drop(
                    columns=['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Target', 'Predictions'], 
                    errors='ignore'
                ).columns

                missing_cols = set(training_feature_columns) - set(X_latest_for_prediction.columns)
                for c in missing_cols:
                    X_latest_for_prediction[c] = 0

                extra_cols = set(X_latest_for_prediction.columns) - set(training_feature_columns)
                X_latest_for_prediction = X_latest_for_prediction.drop(columns=list(extra_cols))
                
                X_latest_for_prediction = X_latest_for_prediction[training_feature_columns]

                X_latest_raw_for_transform = X_latest_for_prediction.values.reshape(1, -1)

                X_latest_scaled = last_scaler.transform(X_latest_raw_for_transform)
                X_latest_pca = last_pca.transform(X_latest_scaled)

                X_latest_selected_pcs = pd.DataFrame(X_latest_pca, columns=[f'PC{j+1}' for j in range(last_pca.n_components_)])
                X_latest_selected_for_prediction = X_latest_selected_pcs.iloc[:, last_selected_pc_indices]

                future_prediction = last_trained_model.predict(X_latest_selected_for_prediction)[0]

                latest_date_available = data['Date'].iloc[-1].strftime('%Y-%m-%d')
                st.write(f"A √∫ltima data de dados dispon√≠vel para an√°lise (baixada pelo yfinance) √©: **{latest_date_available}**")
                st.write(f"Previs√£o de retorno percentual para os pr√≥ximos **5 dias de negocia√ß√£o** a partir desta data: **{future_prediction:.4%}**")
                
                if future_prediction > 0:
                    st.success("O modelo sugere um movimento de **ALTA** nos pr√≥ximos 5 dias de negocia√ß√£o.")
                elif future_prediction < 0:
                    st.error("O modelo sugere um movimento de **BAIXA** nos pr√≥ximos 5 dias de negocia√ß√£o.")
                else:
                    st.info("O modelo sugere um movimento **NEUTRO** nos pr√≥ximos 5 dias de negocia√ß√£o.")
            else:
                st.warning("N√£o foi poss√≠vel gerar indicadores para a previs√£o futura (dados insuficientes ou erro na cria√ß√£o).")
        else:
            st.warning("N√£o foi poss√≠vel gerar a previs√£o futura. Verifique se o pipeline de dados foi executado corretamente e gerou modelos/transformadores v√°lidos.")

        st.success("An√°lise Completa!")

    except Exception as e:
        st.error(f"Ocorreu um erro durante a execu√ß√£o da an√°lise: {e}")
        st.exception(e)

st.markdown("---")
st.markdown("""
### Considera√ß√µes Realistas
√â crucial lembrar que este backtest √© baseado em dados hist√≥ricos e **n√£o garante retornos futuros**. Aspectos como **custos de transa√ß√£o (corretagem, taxas), slippage (diferen√ßa entre pre√ßo esperado e pre√ßo de execu√ß√£o), impostos** e a **capacidade de execu√ß√£o em tempo real** n√£o foram inclu√≠dos. Al√©m disso, a escolha dos par√¢metros (`window_size`, `n_components` do PCA, `num_rounds` da decomposi√ß√£o de bias-vari√¢ncia) s√£o fundamentais para um modelo mais robusto na pr√°tica.

Este aplicativo √© uma base excelente para explorar a decomposi√ß√£o de bias-vari√¢ncia na constru√ß√£o de estrat√©gias de trading. Sinta-se √† vontade para experimentar diferentes modelos, par√¢metros e per√≠odos de dados!
""")
